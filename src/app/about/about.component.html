<div class="row" style="margin-top: 5em;">

    <div class="headline">
        <div>
          <img src="assets/vienna.jpg" alt="bg-img" class="bg-01"/>
        </div>
        <div class="overlay">
            <p class="greet brand-color">
                <i class="fa-solid fa-language"></i> x <i class="fa-solid fa-brain"></i>
            </p>
            <p class="header brand-color">ICML Workshop on</p>
            <h1 class="title brand-color mb-4">
                Large Language Models and Cognition
            </h1>
            <p class="date mb-0"><strong>Date</strong>: July 27th, 2024</p>
            <p class="venu"><strong>Location</strong>: Lehar 3 - Messe Wien Exhibition Congress Center, Vienna, Austria</p>
            <a href="https://icml.cc/virtual/2024/workshop/29963">Link to the event on the ICML website</a>
        </div>
        
    </div>

    <section id="about">
        <h1>About</h1>
        <hr>
        <p>
            Large Language Models (LLMs) have undoubtedly taken center stage in the AI revolution, showing impressive
            performance in a wide variety of tasks, including machine translation, standardized tests, and
            conversational
            chatbots. It is even more impressive to uncover that these models exhibit unpredictable capabilities in
            solving
            unseen tasks. This demonstration of emergent abilities, often credited to the scale of the parameters and
            data
            size in the case of LLMs, is being considered as the footprint of intelligence.
            The goal of this workshop is to assess and understand the position of current LLMs' abilities in the
            landscape of
            intelligent systems, with a strong focus on cognitive abilities. By bringing in experts from different
            scientific
            disciplines, such as AI/ML, neuroscience, cognitive science, and psychology, we aim to discuss topics that
            include but not limited to:</p>
        <ul>
            <li>Where do LLMs stand in terms of performance on cognitive tasks, such as reasoning, navigation,
                planning, and theory of mind?</li>
            <li>What are the fundamental limits of language models with respect to cognitive abilities?</li>
            <li>How do LLMs fine-tuned on specific tasks end-to-end compare to augmented LLMs coupled with
                external modules?</li>
            <li>What are the similarities and differences between mechanistic interpretability approaches in AI and in
                neuroscience? What do they tell us about similarities and differences between LLMs and human brains?
            </li>
            <li>How can we improve existing benchmarks and evaluation methods to rigorously assess cognitive
                abilities in LLMs?</li>
            <li>Can multimodal and multiagent approaches address some of current limits of LLMs to cognitive tasks?</li>
        </ul>
        We hope that this workshop will help identify the gaps and opportunities in the current LLM landscape and shape the path for the development of trustworthy and robust systems guided by cognitive science.
    </section>



</div>